Dec 7, 2013 6:23:02 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Dec 7, 2013 6:23:02 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Command line arguments: {--charset=[UTF-8], --chunkSize=[64], --endPhase=[2147483647], --fileFilterClass=[org.apache.mahout.text.PrefixAdditionFilter], --input=[file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDir], --keyPrefix=[UID], --method=[mapreduce], --output=[file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/mrOutputDir], --startPhase=[0], --tempDir=[temp]}
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapreduce.lib.input.FileInputFormat listStatus
INFO: Total input paths to process : 3
Dec 7, 2013 6:23:02 PM org.apache.hadoop.io.compress.snappy.LoadSnappy <clinit>
WARNING: Snappy native library not loaded
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Running job: job_local_0001
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:02 PM org.apache.hadoop.io.compress.CodecPool getCompressor
INFO: Got brand-new compressor
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0001_m_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.Task commit
INFO: Task attempt_local_0001_m_000000_0 is allowed to commit now
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask
INFO: Saved output of task 'attempt_local_0001_m_000000_0' to file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/mrOutputDir
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:02 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0001_m_000000_0' done.
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO:  map 100% reduce 0%
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Job complete: job_local_0001
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO: Counters: 9
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:   File Output Format Counters 
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Written=277
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:   File Input Format Counters 
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Read=0
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:   FileSystemCounters
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_READ=507
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_WRITTEN=50567
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:   Map-Reduce Framework
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     Map input records=3
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     Spilled Records=0
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     Total committed heap usage (bytes)=85000192
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     SPLIT_RAW_BYTES=357
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output records=3
map.put: UID/test1 This is the first text.
map.put: UID/test2 This is the second text.
map.put: UID/test3 This is the third text.
Dec 7, 2013 6:23:03 PM org.apache.hadoop.io.compress.CodecPool getDecompressor
INFO: Got brand-new decompressor
MR> UID/test1 >> This is the first text.
MR> UID/test2 >> This is the second text.
MR> UID/test3 >> This is the third text.
Dec 7, 2013 6:23:03 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: creativeRecursiveDirFilesFromArrays > based on: file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur
Dec 7, 2013 6:23:03 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Created file: file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur/recursive_test1/file.txt
Dec 7, 2013 6:23:03 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Created file: file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur/recursive_test1/recursive_test2/file.txt
Dec 7, 2013 6:23:03 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Created file: file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur/recursive_test1/recursive_test2/recursive_test3/file.txt
Dec 7, 2013 6:23:03 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: 

 ---- recursive dirs: /tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur/recursive_test1/recursive_test2/recursive_test3,/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur/recursive_test1/recursive_test2,/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur/recursive_test1
Dec 7, 2013 6:23:03 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Command line arguments: {--charset=[UTF-8], --chunkSize=[64], --endPhase=[2147483647], --fileFilterClass=[org.apache.mahout.text.PrefixAdditionFilter], --input=[file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/inputDirRecur], --keyPrefix=[UID], --method=[mapreduce], --output=[file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/mrOutputDirRecur], --startPhase=[0], --tempDir=[temp]}
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapreduce.lib.input.FileInputFormat listStatus
INFO: Total input paths to process : 5
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Running job: job_local_0002
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0002_m_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Task commit
INFO: Task attempt_local_0002_m_000000_0 is allowed to commit now
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask
INFO: Saved output of task 'attempt_local_0002_m_000000_0' to file:/tmp/mahout-TestSequenceFilesFromDirectory-4444797420405144576/mrOutputDirRecur
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:03 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0002_m_000000_0' done.
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO:  map 100% reduce 0%
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Job complete: job_local_0002
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO: Counters: 9
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:   File Output Format Counters 
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Written=382
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:   File Input Format Counters 
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Read=0
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:   FileSystemCounters
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_READ=1684
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_WRITTEN=102186
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:   Map-Reduce Framework
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     Map input records=3
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     Spilled Records=0
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     Total committed heap usage (bytes)=85000192
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     SPLIT_RAW_BYTES=744
Dec 7, 2013 6:23:04 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output records=3
MR-Recur > Trying to check: UID/recursive_test1/recursive_test2/recursive_test3/file.txt
MR-Recur > Trying to check: UID/recursive_test1/recursive_test2/file.txt
MR-Recur > Trying to check: UID/recursive_test1/file.txt
Dec 7, 2013 6:23:04 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Command line arguments: {--charset=[UTF-8], --chunkSize=[64], --endPhase=[2147483647], --fileFilterClass=[org.apache.mahout.text.PrefixAdditionFilter], --input=[file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDir], --keyPrefix=[UID], --method=[sequential], --output=[file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/outputDir], --startPhase=[0], --tempDir=[temp]}
Dec 7, 2013 6:23:04 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: creativeRecursiveDirFilesFromArrays > based on: file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur
Dec 7, 2013 6:23:04 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Created file: file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur/recursive_test1/file.txt
Dec 7, 2013 6:23:04 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Created file: file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur/recursive_test1/recursive_test2/file.txt
Dec 7, 2013 6:23:04 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Created file: file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur/recursive_test1/recursive_test2/recursive_test3/file.txt


 ----- recursive dirs: /tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur/recursive_test1/recursive_test2/recursive_test3,/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur/recursive_test1/recursive_test2,/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur/recursive_test1
Dec 7, 2013 6:23:04 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Command line arguments: {--charset=[UTF-8], --chunkSize=[64], --endPhase=[2147483647], --fileFilterClass=[org.apache.mahout.text.PrefixAdditionFilter], --input=[file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/inputDirRecur], --keyPrefix=[UID], --method=[sequential], --output=[file:/tmp/mahout-TestSequenceFilesFromDirectory-2677982242862446592/outputDirRecursive], --startPhase=[0], --tempDir=[temp]}
 ----------- check_Recursive_ChunkFiles ------------
UID/recursive_test1/file.txt >> This is the first text.
>>> k: UID/recursive_test1/file.txt, v: This is the first text.

UID/recursive_test1/recursive_test2/file.txt >> This is the second text.
>>> k: UID/recursive_test1/recursive_test2/file.txt, v: This is the second text.

UID/recursive_test1/recursive_test2/recursive_test3/file.txt >> This is the third text.
>>> k: UID/recursive_test1/recursive_test2/recursive_test3/file.txt, v: This is the third text.

