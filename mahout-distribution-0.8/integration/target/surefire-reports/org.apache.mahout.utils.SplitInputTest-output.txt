Dec 7, 2013 6:23:07 PM org.apache.hadoop.util.NativeCodeLoader <clinit>
WARNING: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Dec 7, 2013 6:23:07 PM org.apache.hadoop.io.compress.CodecPool getCompressor
INFO: Got brand-new compressor
Dec 7, 2013 6:23:07 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Command line arguments: {--endPhase=[2147483647], --input=[file:/tmp/mahout-SplitInputTest-3624109446095668224/tmpsequence], --keepPct=[10], --mapRedOutputDir=[file:/tmp/mahout-SplitInputTest-3624109446095668224/mapRedOutput], --method=[mapreduce], --overwrite=null, --randomSelectionPct=[25], --startPhase=[0], --tempDir=[temp]}
Dec 7, 2013 6:23:07 PM org.apache.hadoop.io.compress.CodecPool getDecompressor
INFO: Got brand-new decompressor
Dec 7, 2013 6:23:07 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapreduce.lib.input.FileInputFormat listStatus
INFO: Total input paths to process : 1
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Running job: job_local_0001
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: io.sort.mb = 100
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: data buffer = 79691776/99614720
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: record buffer = 262144/327680
Dec 7, 2013 6:23:08 PM org.apache.hadoop.io.compress.CodecPool getDecompressor
INFO: Got brand-new decompressor
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer flush
INFO: Starting flush of map output
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer sortAndSpill
INFO: Finished spill 0
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0001_m_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0001_m_000000_0' done.
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Merging 1 sorted segments
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Down to the last merge-pass, with 1 segments left of total size: 1480 bytes
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0001_r_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Task commit
INFO: Task attempt_local_0001_r_000000_0 is allowed to commit now
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask
INFO: Saved output of task 'attempt_local_0001_r_000000_0' to file:/tmp/mahout-SplitInputTest-3624109446095668224/mapRedOutput
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: reduce > reduce
Dec 7, 2013 6:23:08 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0001_r_000000_0' done.
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO:  map 100% reduce 100%
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Job complete: job_local_0001
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO: Counters: 17
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:   File Output Format Counters 
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Written=90
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:   FileSystemCounters
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_READ=69372
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_WRITTEN=169070
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:   File Input Format Counters 
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Read=29417
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:   Map-Reduce Framework
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output materialized bytes=1484
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Map input records=1000
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce shuffle bytes=0
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Spilled Records=200
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output bytes=1278
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Total committed heap usage (bytes)=369238016
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     SPLIT_RAW_BYTES=139
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine input records=0
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input records=100
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input groups=100
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine output records=0
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce output records=0
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output records=100
Test data: 25 records
310	Line 310
570	Line 570
830	Line 830
230	Line 230
120	Line 120
20	Line 20
500	Line 500
180	Line 180
140	Line 140
870	Line 870
540	Line 540
40	Line 40
990	Line 990
240	Line 240
300	Line 300
900	Line 900
580	Line 580
470	Line 470
780	Line 780
690	Line 690
880	Line 880
910	Line 910
550	Line 550
280	Line 280
980	Line 980
Training data: 75 records
340	Line 340
490	Line 490
890	Line 890
930	Line 930
90	Line 90
250	Line 250
440	Line 440
390	Line 390
760	Line 760
10	Line 10
820	Line 820
750	Line 750
170	Line 170
920	Line 920
350	Line 350
600	Line 600
70	Line 70
100	Line 100
410	Line 410
420	Line 420
790	Line 790
950	Line 950
800	Line 800
480	Line 480
130	Line 130
320	Line 320
970	Line 970
650	Line 650
370	Line 370
80	Line 80
560	Line 560
60	Line 60
50	Line 50
770	Line 770
460	Line 460
680	Line 680
0	Line 0
30	Line 30
620	Line 620
290	Line 290
260	Line 260
670	Line 670
150	Line 150
220	Line 220
200	Line 200
330	Line 330
860	Line 860
850	Line 850
730	Line 730
160	Line 160
400	Line 400
520	Line 520
380	Line 380
740	Line 740
110	Line 110
450	Line 450
270	Line 270
510	Line 510
660	Line 660
590	Line 590
960	Line 960
530	Line 530
700	Line 700
640	Line 640
430	Line 430
810	Line 810
610	Line 610
720	Line 720
940	Line 940
210	Line 210
630	Line 630
190	Line 190
840	Line 840
360	Line 360
710	Line 710
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: lucene has 4 lines
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: lucene test split size is 1
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: lucene test split start is 3 based on split location 100
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: lucene, input: 4 train: 3, test: 1 starting at 3
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: mahout has 4 lines
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: mahout test split size is 1
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: mahout test split start is 3 based on split location 100
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: mahout, input: 4 train: 3, test: 1 starting at 3
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: spamassasin has 4 lines
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: spamassasin test split size is 1
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: spamassasin test split start is 3 based on split location 100
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: spamassasin, input: 4 train: 3, test: 1 starting at 3
Dec 7, 2013 6:23:09 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: Command line arguments: {--endPhase=[2147483647], --input=[file:/tmp/mahout-SplitInputTest-712970379895741440/tmpsequence], --keepPct=[10], --mapRedOutputDir=[file:/tmp/mahout-SplitInputTest-712970379895741440/mapRedOutput], --method=[mapreduce], --overwrite=null, --randomSelectionPct=[25], --startPhase=[0], --tempDir=[temp]}
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapreduce.lib.input.FileInputFormat listStatus
INFO: Total input paths to process : 1
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Running job: job_local_0002
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: io.sort.mb = 100
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: data buffer = 79691776/99614720
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: record buffer = 262144/327680
Dec 7, 2013 6:23:09 PM org.apache.hadoop.io.compress.CodecPool getDecompressor
INFO: Got brand-new decompressor
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer flush
INFO: Starting flush of map output
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer sortAndSpill
INFO: Finished spill 0
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0002_m_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0002_m_000000_0' done.
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Merging 1 sorted segments
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Down to the last merge-pass, with 1 segments left of total size: 4466 bytes
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0002_r_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Task commit
INFO: Task attempt_local_0002_r_000000_0 is allowed to commit now
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask
INFO: Saved output of task 'attempt_local_0002_r_000000_0' to file:/tmp/mahout-SplitInputTest-712970379895741440/mapRedOutput
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: reduce > reduce
Dec 7, 2013 6:23:09 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0002_r_000000_0' done.
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO:  map 100% reduce 100%
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Job complete: job_local_0002
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO: Counters: 17
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:   File Output Format Counters 
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Written=109
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:   FileSystemCounters
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_READ=183130
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_WRITTEN=372425
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:   File Input Format Counters 
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Read=32583
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:   Map-Reduce Framework
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output materialized bytes=4470
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Map input records=1000
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce shuffle bytes=0
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Spilled Records=200
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output bytes=4264
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Total committed heap usage (bytes)=397246464
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     SPLIT_RAW_BYTES=138
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine input records=0
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input records=100
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input groups=100
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine output records=0
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce output records=0
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output records=100
Test data: 25 records
310	{0:310.0,1:310.0,2:310.0,3:310.0,}
570	{0:570.0,1:570.0,2:570.0,3:570.0,}
830	{0:830.0,1:830.0,2:830.0,3:830.0,}
230	{0:230.0,1:230.0,2:230.0,3:230.0,}
120	{0:120.0,1:120.0,2:120.0,3:120.0,}
20	{0:20.0,1:20.0,2:20.0,3:20.0,}
500	{0:500.0,1:500.0,2:500.0,3:500.0,}
180	{0:180.0,1:180.0,2:180.0,3:180.0,}
140	{0:140.0,1:140.0,2:140.0,3:140.0,}
870	{0:870.0,1:870.0,2:870.0,3:870.0,}
540	{0:540.0,1:540.0,2:540.0,3:540.0,}
40	{0:40.0,1:40.0,2:40.0,3:40.0,}
990	{0:990.0,1:990.0,2:990.0,3:990.0,}
240	{0:240.0,1:240.0,2:240.0,3:240.0,}
300	{0:300.0,1:300.0,2:300.0,3:300.0,}
900	{0:900.0,1:900.0,2:900.0,3:900.0,}
580	{0:580.0,1:580.0,2:580.0,3:580.0,}
470	{0:470.0,1:470.0,2:470.0,3:470.0,}
780	{0:780.0,1:780.0,2:780.0,3:780.0,}
690	{0:690.0,1:690.0,2:690.0,3:690.0,}
880	{0:880.0,1:880.0,2:880.0,3:880.0,}
910	{0:910.0,1:910.0,2:910.0,3:910.0,}
550	{0:550.0,1:550.0,2:550.0,3:550.0,}
280	{0:280.0,1:280.0,2:280.0,3:280.0,}
980	{0:980.0,1:980.0,2:980.0,3:980.0,}
Training data: 75 records
340	{0:340.0,1:340.0,2:340.0,3:340.0,}
490	{0:490.0,1:490.0,2:490.0,3:490.0,}
890	{0:890.0,1:890.0,2:890.0,3:890.0,}
930	{0:930.0,1:930.0,2:930.0,3:930.0,}
90	{0:90.0,1:90.0,2:90.0,3:90.0,}
250	{0:250.0,1:250.0,2:250.0,3:250.0,}
440	{0:440.0,1:440.0,2:440.0,3:440.0,}
390	{0:390.0,1:390.0,2:390.0,3:390.0,}
760	{0:760.0,1:760.0,2:760.0,3:760.0,}
10	{0:10.0,1:10.0,2:10.0,3:10.0,}
820	{0:820.0,1:820.0,2:820.0,3:820.0,}
750	{0:750.0,1:750.0,2:750.0,3:750.0,}
170	{0:170.0,1:170.0,2:170.0,3:170.0,}
920	{0:920.0,1:920.0,2:920.0,3:920.0,}
350	{0:350.0,1:350.0,2:350.0,3:350.0,}
600	{0:600.0,1:600.0,2:600.0,3:600.0,}
70	{0:70.0,1:70.0,2:70.0,3:70.0,}
100	{0:100.0,1:100.0,2:100.0,3:100.0,}
410	{0:410.0,1:410.0,2:410.0,3:410.0,}
420	{0:420.0,1:420.0,2:420.0,3:420.0,}
790	{0:790.0,1:790.0,2:790.0,3:790.0,}
950	{0:950.0,1:950.0,2:950.0,3:950.0,}
800	{0:800.0,1:800.0,2:800.0,3:800.0,}
480	{0:480.0,1:480.0,2:480.0,3:480.0,}
130	{0:130.0,1:130.0,2:130.0,3:130.0,}
320	{0:320.0,1:320.0,2:320.0,3:320.0,}
970	{0:970.0,1:970.0,2:970.0,3:970.0,}
650	{0:650.0,1:650.0,2:650.0,3:650.0,}
370	{0:370.0,1:370.0,2:370.0,3:370.0,}
80	{0:80.0,1:80.0,2:80.0,3:80.0,}
560	{0:560.0,1:560.0,2:560.0,3:560.0,}
60	{0:60.0,1:60.0,2:60.0,3:60.0,}
50	{0:50.0,1:50.0,2:50.0,3:50.0,}
770	{0:770.0,1:770.0,2:770.0,3:770.0,}
460	{0:460.0,1:460.0,2:460.0,3:460.0,}
680	{0:680.0,1:680.0,2:680.0,3:680.0,}
0	{}
30	{0:30.0,1:30.0,2:30.0,3:30.0,}
620	{0:620.0,1:620.0,2:620.0,3:620.0,}
290	{0:290.0,1:290.0,2:290.0,3:290.0,}
260	{0:260.0,1:260.0,2:260.0,3:260.0,}
670	{0:670.0,1:670.0,2:670.0,3:670.0,}
150	{0:150.0,1:150.0,2:150.0,3:150.0,}
220	{0:220.0,1:220.0,2:220.0,3:220.0,}
200	{0:200.0,1:200.0,2:200.0,3:200.0,}
330	{0:330.0,1:330.0,2:330.0,3:330.0,}
860	{0:860.0,1:860.0,2:860.0,3:860.0,}
850	{0:850.0,1:850.0,2:850.0,3:850.0,}
730	{0:730.0,1:730.0,2:730.0,3:730.0,}
160	{0:160.0,1:160.0,2:160.0,3:160.0,}
400	{0:400.0,1:400.0,2:400.0,3:400.0,}
520	{0:520.0,1:520.0,2:520.0,3:520.0,}
380	{0:380.0,1:380.0,2:380.0,3:380.0,}
740	{0:740.0,1:740.0,2:740.0,3:740.0,}
110	{0:110.0,1:110.0,2:110.0,3:110.0,}
450	{0:450.0,1:450.0,2:450.0,3:450.0,}
270	{0:270.0,1:270.0,2:270.0,3:270.0,}
510	{0:510.0,1:510.0,2:510.0,3:510.0,}
660	{0:660.0,1:660.0,2:660.0,3:660.0,}
590	{0:590.0,1:590.0,2:590.0,3:590.0,}
960	{0:960.0,1:960.0,2:960.0,3:960.0,}
530	{0:530.0,1:530.0,2:530.0,3:530.0,}
700	{0:700.0,1:700.0,2:700.0,3:700.0,}
640	{0:640.0,1:640.0,2:640.0,3:640.0,}
430	{0:430.0,1:430.0,2:430.0,3:430.0,}
810	{0:810.0,1:810.0,2:810.0,3:810.0,}
610	{0:610.0,1:610.0,2:610.0,3:610.0,}
720	{0:720.0,1:720.0,2:720.0,3:720.0,}
940	{0:940.0,1:940.0,2:940.0,3:940.0,}
210	{0:210.0,1:210.0,2:210.0,3:210.0,}
630	{0:630.0,1:630.0,2:630.0,3:630.0,}
190	{0:190.0,1:190.0,2:190.0,3:190.0,}
840	{0:840.0,1:840.0,2:840.0,3:840.0,}
360	{0:360.0,1:360.0,2:360.0,3:360.0,}
710	{0:710.0,1:710.0,2:710.0,3:710.0,}
Dec 7, 2013 6:23:10 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile has 12 lines
Dec 7, 2013 6:23:10 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split size is 3 based on percentage 25
Dec 7, 2013 6:23:10 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split start is 9 based on split location 100
Dec 7, 2013 6:23:10 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: bayesinputfile, input: 12 train: 9, test: 3 starting at 9
Dec 7, 2013 6:23:10 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile has 12 lines
Dec 7, 2013 6:23:10 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split size is 3 based on random selection percentage 25
Dec 7, 2013 6:23:10 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: bayesinputfile, input: 12 train: 9, test: 3 starting at 0
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapreduce.lib.input.FileInputFormat listStatus
INFO: Total input paths to process : 1
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Running job: job_local_0003
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: io.sort.mb = 100
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: data buffer = 79691776/99614720
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: record buffer = 262144/327680
Dec 7, 2013 6:23:10 PM org.apache.hadoop.io.compress.CodecPool getDecompressor
INFO: Got brand-new decompressor
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer flush
INFO: Starting flush of map output
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer sortAndSpill
INFO: Finished spill 0
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0003_m_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0003_m_000000_0' done.
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Merging 1 sorted segments
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Down to the last merge-pass, with 1 segments left of total size: 4466 bytes
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0003_r_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Task commit
INFO: Task attempt_local_0003_r_000000_0 is allowed to commit now
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask
INFO: Saved output of task 'attempt_local_0003_r_000000_0' to file:/tmp/mahout-SplitInputTest-3655987718352739328/mapRedOutput
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: reduce > reduce
Dec 7, 2013 6:23:10 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0003_r_000000_0' done.
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO:  map 100% reduce 100%
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Job complete: job_local_0003
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO: Counters: 17
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:   File Output Format Counters 
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Written=109
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:   FileSystemCounters
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_READ=336262
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_WRITTEN=594517
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:   File Input Format Counters 
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Read=32583
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:   Map-Reduce Framework
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output materialized bytes=4470
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Map input records=1000
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce shuffle bytes=0
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Spilled Records=200
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output bytes=4264
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Total committed heap usage (bytes)=397246464
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     SPLIT_RAW_BYTES=139
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine input records=0
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input records=100
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input groups=100
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine output records=0
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce output records=0
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output records=100
Test data: 25 records
310	{0:310.0,1:310.0,2:310.0,3:310.0,}
570	{0:570.0,1:570.0,2:570.0,3:570.0,}
830	{0:830.0,1:830.0,2:830.0,3:830.0,}
230	{0:230.0,1:230.0,2:230.0,3:230.0,}
120	{0:120.0,1:120.0,2:120.0,3:120.0,}
20	{0:20.0,1:20.0,2:20.0,3:20.0,}
500	{0:500.0,1:500.0,2:500.0,3:500.0,}
180	{0:180.0,1:180.0,2:180.0,3:180.0,}
140	{0:140.0,1:140.0,2:140.0,3:140.0,}
870	{0:870.0,1:870.0,2:870.0,3:870.0,}
540	{0:540.0,1:540.0,2:540.0,3:540.0,}
40	{0:40.0,1:40.0,2:40.0,3:40.0,}
990	{0:990.0,1:990.0,2:990.0,3:990.0,}
240	{0:240.0,1:240.0,2:240.0,3:240.0,}
300	{0:300.0,1:300.0,2:300.0,3:300.0,}
900	{0:900.0,1:900.0,2:900.0,3:900.0,}
580	{0:580.0,1:580.0,2:580.0,3:580.0,}
470	{0:470.0,1:470.0,2:470.0,3:470.0,}
780	{0:780.0,1:780.0,2:780.0,3:780.0,}
690	{0:690.0,1:690.0,2:690.0,3:690.0,}
880	{0:880.0,1:880.0,2:880.0,3:880.0,}
910	{0:910.0,1:910.0,2:910.0,3:910.0,}
550	{0:550.0,1:550.0,2:550.0,3:550.0,}
280	{0:280.0,1:280.0,2:280.0,3:280.0,}
980	{0:980.0,1:980.0,2:980.0,3:980.0,}
Training data: 75 records
340	{0:340.0,1:340.0,2:340.0,3:340.0,}
490	{0:490.0,1:490.0,2:490.0,3:490.0,}
890	{0:890.0,1:890.0,2:890.0,3:890.0,}
930	{0:930.0,1:930.0,2:930.0,3:930.0,}
90	{0:90.0,1:90.0,2:90.0,3:90.0,}
250	{0:250.0,1:250.0,2:250.0,3:250.0,}
440	{0:440.0,1:440.0,2:440.0,3:440.0,}
390	{0:390.0,1:390.0,2:390.0,3:390.0,}
760	{0:760.0,1:760.0,2:760.0,3:760.0,}
10	{0:10.0,1:10.0,2:10.0,3:10.0,}
820	{0:820.0,1:820.0,2:820.0,3:820.0,}
750	{0:750.0,1:750.0,2:750.0,3:750.0,}
170	{0:170.0,1:170.0,2:170.0,3:170.0,}
920	{0:920.0,1:920.0,2:920.0,3:920.0,}
350	{0:350.0,1:350.0,2:350.0,3:350.0,}
600	{0:600.0,1:600.0,2:600.0,3:600.0,}
70	{0:70.0,1:70.0,2:70.0,3:70.0,}
100	{0:100.0,1:100.0,2:100.0,3:100.0,}
410	{0:410.0,1:410.0,2:410.0,3:410.0,}
420	{0:420.0,1:420.0,2:420.0,3:420.0,}
790	{0:790.0,1:790.0,2:790.0,3:790.0,}
950	{0:950.0,1:950.0,2:950.0,3:950.0,}
800	{0:800.0,1:800.0,2:800.0,3:800.0,}
480	{0:480.0,1:480.0,2:480.0,3:480.0,}
130	{0:130.0,1:130.0,2:130.0,3:130.0,}
320	{0:320.0,1:320.0,2:320.0,3:320.0,}
970	{0:970.0,1:970.0,2:970.0,3:970.0,}
650	{0:650.0,1:650.0,2:650.0,3:650.0,}
370	{0:370.0,1:370.0,2:370.0,3:370.0,}
80	{0:80.0,1:80.0,2:80.0,3:80.0,}
560	{0:560.0,1:560.0,2:560.0,3:560.0,}
60	{0:60.0,1:60.0,2:60.0,3:60.0,}
50	{0:50.0,1:50.0,2:50.0,3:50.0,}
770	{0:770.0,1:770.0,2:770.0,3:770.0,}
460	{0:460.0,1:460.0,2:460.0,3:460.0,}
680	{0:680.0,1:680.0,2:680.0,3:680.0,}
0	{}
30	{0:30.0,1:30.0,2:30.0,3:30.0,}
620	{0:620.0,1:620.0,2:620.0,3:620.0,}
290	{0:290.0,1:290.0,2:290.0,3:290.0,}
260	{0:260.0,1:260.0,2:260.0,3:260.0,}
670	{0:670.0,1:670.0,2:670.0,3:670.0,}
150	{0:150.0,1:150.0,2:150.0,3:150.0,}
220	{0:220.0,1:220.0,2:220.0,3:220.0,}
200	{0:200.0,1:200.0,2:200.0,3:200.0,}
330	{0:330.0,1:330.0,2:330.0,3:330.0,}
860	{0:860.0,1:860.0,2:860.0,3:860.0,}
850	{0:850.0,1:850.0,2:850.0,3:850.0,}
730	{0:730.0,1:730.0,2:730.0,3:730.0,}
160	{0:160.0,1:160.0,2:160.0,3:160.0,}
400	{0:400.0,1:400.0,2:400.0,3:400.0,}
520	{0:520.0,1:520.0,2:520.0,3:520.0,}
380	{0:380.0,1:380.0,2:380.0,3:380.0,}
740	{0:740.0,1:740.0,2:740.0,3:740.0,}
110	{0:110.0,1:110.0,2:110.0,3:110.0,}
450	{0:450.0,1:450.0,2:450.0,3:450.0,}
270	{0:270.0,1:270.0,2:270.0,3:270.0,}
510	{0:510.0,1:510.0,2:510.0,3:510.0,}
660	{0:660.0,1:660.0,2:660.0,3:660.0,}
590	{0:590.0,1:590.0,2:590.0,3:590.0,}
960	{0:960.0,1:960.0,2:960.0,3:960.0,}
530	{0:530.0,1:530.0,2:530.0,3:530.0,}
700	{0:700.0,1:700.0,2:700.0,3:700.0,}
640	{0:640.0,1:640.0,2:640.0,3:640.0,}
430	{0:430.0,1:430.0,2:430.0,3:430.0,}
810	{0:810.0,1:810.0,2:810.0,3:810.0,}
610	{0:610.0,1:610.0,2:610.0,3:610.0,}
720	{0:720.0,1:720.0,2:720.0,3:720.0,}
940	{0:940.0,1:940.0,2:940.0,3:940.0,}
210	{0:210.0,1:210.0,2:210.0,3:210.0,}
630	{0:630.0,1:630.0,2:630.0,3:630.0,}
190	{0:190.0,1:190.0,2:190.0,3:190.0,}
840	{0:840.0,1:840.0,2:840.0,3:840.0,}
360	{0:360.0,1:360.0,2:360.0,3:360.0,}
710	{0:710.0,1:710.0,2:710.0,3:710.0,}
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile has 12 lines
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split size is 5 based on random selection percentage -1
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: bayesinputfile, input: 12 train: 7, test: 5 starting at 0
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile has 12 lines
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split size is 2
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split start is 6 based on split location 50
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: bayesinputfile, input: 12 train: 10, test: 2 starting at 6
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile has 12 lines
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split size is 2
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split start is 10 based on split location 100
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: bayesinputfile, input: 12 train: 10, test: 2 starting at 10
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile has 12 lines
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split size is 3 based on percentage 25
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: bayesinputfile test split start is 6 based on split location 50
Dec 7, 2013 6:23:11 PM org.slf4j.impl.JCLLoggerAdapter info
INFO: file: bayesinputfile, input: 12 train: 9, test: 3 starting at 6
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same.
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.JobClient copyAndConfigureFiles
WARNING: No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapreduce.lib.input.FileInputFormat listStatus
INFO: Total input paths to process : 1
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Running job: job_local_0004
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: io.sort.mb = 100
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: data buffer = 79691776/99614720
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer <init>
INFO: record buffer = 262144/327680
Dec 7, 2013 6:23:11 PM org.apache.hadoop.io.compress.CodecPool getDecompressor
INFO: Got brand-new decompressor
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer flush
INFO: Starting flush of map output
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.MapTask$MapOutputBuffer sortAndSpill
INFO: Finished spill 0
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0004_m_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0004_m_000000_0' done.
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Task initialize
INFO:  Using ResourceCalculatorPlugin : null
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Merging 1 sorted segments
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Merger$MergeQueue merge
INFO: Down to the last merge-pass, with 1 segments left of total size: 1480 bytes
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Task done
INFO: Task:attempt_local_0004_r_000000_0 is done. And is in the process of commiting
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: 
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Task commit
INFO: Task attempt_local_0004_r_000000_0 is allowed to commit now
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter commitTask
INFO: Saved output of task 'attempt_local_0004_r_000000_0' to file:/tmp/mahout-SplitInputTest-2357938425677035520/mapRedOutput
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.LocalJobRunner$Job statusUpdate
INFO: reduce > reduce
Dec 7, 2013 6:23:11 PM org.apache.hadoop.mapred.Task sendDone
INFO: Task 'attempt_local_0004_r_000000_0' done.
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO:  map 100% reduce 100%
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.JobClient monitorAndPrintJob
INFO: Job complete: job_local_0004
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO: Counters: 17
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:   File Output Format Counters 
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Written=90
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:   FileSystemCounters
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_READ=528584
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     FILE_BYTES_WRITTEN=833386
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:   File Input Format Counters 
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Bytes Read=29417
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:   Map-Reduce Framework
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output materialized bytes=1484
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Map input records=1000
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce shuffle bytes=0
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Spilled Records=200
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output bytes=1278
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Total committed heap usage (bytes)=397246464
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     SPLIT_RAW_BYTES=139
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine input records=0
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input records=100
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce input groups=100
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Combine output records=0
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Reduce output records=0
Dec 7, 2013 6:23:12 PM org.apache.hadoop.mapred.Counters log
INFO:     Map output records=100
Test data: 25 records
310	Line 310
570	Line 570
830	Line 830
230	Line 230
120	Line 120
20	Line 20
500	Line 500
180	Line 180
140	Line 140
870	Line 870
540	Line 540
40	Line 40
990	Line 990
240	Line 240
300	Line 300
900	Line 900
580	Line 580
470	Line 470
780	Line 780
690	Line 690
880	Line 880
910	Line 910
550	Line 550
280	Line 280
980	Line 980
Training data: 75 records
340	Line 340
490	Line 490
890	Line 890
930	Line 930
90	Line 90
250	Line 250
440	Line 440
390	Line 390
760	Line 760
10	Line 10
820	Line 820
750	Line 750
170	Line 170
920	Line 920
350	Line 350
600	Line 600
70	Line 70
100	Line 100
410	Line 410
420	Line 420
790	Line 790
950	Line 950
800	Line 800
480	Line 480
130	Line 130
320	Line 320
970	Line 970
650	Line 650
370	Line 370
80	Line 80
560	Line 560
60	Line 60
50	Line 50
770	Line 770
460	Line 460
680	Line 680
0	Line 0
30	Line 30
620	Line 620
290	Line 290
260	Line 260
670	Line 670
150	Line 150
220	Line 220
200	Line 200
330	Line 330
860	Line 860
850	Line 850
730	Line 730
160	Line 160
400	Line 400
520	Line 520
380	Line 380
740	Line 740
110	Line 110
450	Line 450
270	Line 270
510	Line 510
660	Line 660
590	Line 590
960	Line 960
530	Line 530
700	Line 700
640	Line 640
430	Line 430
810	Line 810
610	Line 610
720	Line 720
940	Line 940
210	Line 210
630	Line 630
190	Line 190
840	Line 840
360	Line 360
710	Line 710
